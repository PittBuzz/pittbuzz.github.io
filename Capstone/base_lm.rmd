---
title: "Build a baseline Regression Model"
author: "J. Voltz"
date: "9/27/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Predict Hourly Rented Bike Count using Basic Linear Regression Models

Now that you have performed exploratory analysis on the bike sharing demand dataset and obtained some insights on the attributes, it's time to build predictive models to predict the hourly rented bike count using related weather and date information.


    TASK: Split data into training and testing datasets
    TASK: Build a linear regression model using only the weather variables
    TASK: Build a linear regression model using both weather and date variables
    TASK: Evaluate the models and identify important variables


```{r install}
# It may take several minutes to install those libraries in Watson Studio
#install.packages("rlang")
#install.packages("tidymodels")

library("tidymodels")
library("tidyverse")
library("stringr")
```

The response variable:

    RENTED BIKE COUNT- Count of bikes rented at each hour

Weather predictor variables:

    TEMPERATURE - Temperature in Celsius
    HUMIDITY - Unit is %
    WIND_SPEED - Unit is m/s
    VISIBILITY - Multiplied by 10m
    DEW_POINT_TEMPERATURE - The temperature to which the air would have to cool down in order to reach saturation, unit is Celsius
    SOLAR_RADIATION - MJ/m2
    RAINFALL - mm
    SNOWFALL - cm

Date/time predictor variables:

    DATE - Year-month-day
    HOUR- Hour of he day
    FUNCTIONAL DAY - NoFunc(Non Functional Hours), Fun(Functional hours)
    HOLIDAY - Holiday/No holiday
    SEASONS - Winter, Spring, Summer, Autumn



```{r data}
# Dataset URL
dataset_url <- "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/seoul_bike_sharing_converted_normalized.csv"
bike_sharing_df <- read_csv(dataset_url)
spec(bike_sharing_df)
```


Remove date and functional day
```{r}
bike_sharing_df <- bike_sharing_df %>% 
                   select(-DATE, -FUNCTIONING_DAY)
```

## TASK: Split training and testing data

First, we need to split the full dataset into training and testing datasets.

The training dataset will be used for fitting regression models, and the testing dataset will be used to evaluate the trained models.

```{r dataset}
# Use the `initial_split()`, `training()`, and `testing()` functions to split the dataset
# With seed 1234
set.seed(1234)
data_split <- initial_split(bike_sharing_df, prop = 3/4)
# train_data 
train_data <- training(data_split)
# test_data
test_data <- testing(data_split)
```

## TASK: Build a linear regression model using weather variables only

As you could imagine, weather conditions may affect people's bike renting decisions. For example, on a cold and rainy day, you may choose alternate transportation such as a bus or taxi. While on a nice sunny day, you may want to rent a bike for a short-distance travel.

```{r}
# Use `linear_reg()` with engine `lm` and mode `regression`
lm_spec <- linear_reg() %>%
  set_engine("lm") %>% 
  set_mode("regression")
```

```{r}
# Fit the model called `lm_model_weather`
# RENTED_BIKE_COUNT ~ TEMPERATURE + HUMIDITY + WIND_SPEED + VISIBILITY + DEW_POINT_TEMPERATURE + SOLAR_RADIATION + RAINFALL + SNOWFALL,  with the training data
lm_model_weather <- lm_spec %>%
  fit(data = train_data, RENTED_BIKE_COUNT ~ TEMPERATURE 
                       + HUMIDITY 
                       + WIND_SPEED 
                       + VISIBILITY 
                       + DEW_POINT_TEMPERATURE 
                       + SOLAR_RADIATION 
                       + RAINFALL 
                       + SNOWFALL)
lm_model_all <- lm_spec %>% 
  fit(RENTED_BIKE_COUNT ~ ., data = train_data)
```

```{r}
summary(lm_model_weather)
```

## TASK: Build a linear regression model using all variables

In addition to weather, there could be other factors that may affect bike rental demand, such as the time of a day or if today is a holiday or not.

```{r}
# Fit the model called `lm_model_all`
# `RENTED_BIKE_COUNT ~ .` means use all other variables except for the response variable
 lm_model_all <- lm_model_all <- lm_spec %>% 
  fit(RENTED_BIKE_COUNT ~ ., data = train_data)
```

```{r}
summary(lm_model_all$fit)
```

## TASK: Model evaluation and identification of important variables

Now that you have built two regression models, lm_model_weather and lm_model_all, with different predictor variables, you need to compare their performance to see which one is better.

```{r}
# Use predict() function to generate test results for `lm_model_weather` and `lm_model_all`
# and generate two test results dataframe with a truth column:

# test_results_weather for lm_model_weather model
#pred_weather <- data.frame(test_data)
# test_results_all for lm_model_all
#pred_all <- data.frame(predict(lm_model_all, truth = RENTED_BIKE_COUNT))
#pred_all <- data.frame(test_data)

#preddf <- data.frame(pred_weather, pred_all)
test_results_weather <- lm_model_weather %>%
  predict(new_data = test_data) %>%
  mutate(truth = test_data$RENTED_BIKE_COUNT)

test_results_all <- lm_model_all %>%
  predict(new_data = test_data) %>%
  mutate(truth = test_data$RENTED_BIKE_COUNT)
```

Next, let's calculate and print the R-squared and RMSE for the two test results

```{r}
rsq_weather <- rsq(test_results_weather, truth, .pred)
rsq_all <- rsq(test_results_all, truth, .pred)

rmse_weather <- rmse(test_results_weather, truth, .pred)
rmse_all <- rmse(test_results_all, truth, .pred)

rsq_weather
rsq_all
rmse_weather
rmse_all
```

From these tables, you should find that the test results from lm_model_all are much better. It means that using both weather and datetime variables in the model generates better prediction results.

Since lm_model_all has many predictor variables, let's check which predictor variables have larger coefficients. Variables with larger coefficients in the model means they attribute more in the prediction of RENTED_BIKE_COUNT. In addition, since all predictor variables are normalized to the same scale, 0 to 1, we thus can compare their coefficients directly.

You could try building another regression model using the non-normalized seoul_bike_sharing_converted.csv dataset, and you would find that the coefficients are much different.

```{r}
# print all coefficients
lm_model_all$fit$coefficients
```

hmm, it's not very clear to compare the coefficients from a long and unsorted list. Next, you need to sort and visualize them using a bar chart

```{r}
#sort(lm_model_all$coefficients, decreasing = TRUE)
abs_cof_df <- stack(abs(lm_model_all$fit$coefficients))
names(abs_cof_df) <- c("Coef", "Variable")
abs_cof_df <- abs_cof_df %>% 
                select(Variable, Coef)
coefs_sorted <- arrange(abs_cof_df, -Coef) 
coefs_sorted <- na.omit(coefs_sorted)

coefs_sorted
```

```{r}
ggplot(data=coefs_sorted, aes(x= reorder(Variable,Coef),Coef)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  theme_minimal()
```

